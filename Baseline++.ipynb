{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline++.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier"
      ],
      "metadata": {
        "id": "DLYxhylcBmUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Data"
      ],
      "metadata": {
        "id": "WlVOLbIr-ZdA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6lcWRW-6TQH"
      },
      "outputs": [],
      "source": [
        "# !wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "# !tar xvf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.aligned.cased_nopunct.tsv\"\n",
        "rawData = open(path)\n",
        "reader = csv.reader(rawData, delimiter=\"\\t\")\n",
        "dataset = []"
      ],
      "metadata": {
        "id": "CGkWhEdl7kHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = []\n",
        "pair = []\n",
        "sent = []\n",
        "i = 0\n",
        "rowno = 1\n",
        "for row in reader:\n",
        "\n",
        "    if row[0] == \"</s>\":\n",
        "        dataset.append(sent)\n",
        "        sent = []\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        pair.append(row[0])\n",
        "        pair.append(row[1])\n",
        "        sent.append(pair)\n",
        "        pair = []\n",
        "    except IndexError:\n",
        "        error.append(rowno)\n",
        "\n",
        "    rowno += 1"
      ],
      "metadata": {
        "id": "27ANyeUz9ssd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset[:6000]\n",
        "dev_data = dataset[6000:8000]\n",
        "test_data = dataset[8000:]"
      ],
      "metadata": {
        "id": "8XBWedH49xGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Handling"
      ],
      "metadata": {
        "id": "b85Qy1ZHCat9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_lower_script = [chr(alpha) for alpha in range(97, 123)]\n",
        "devanagari_script = [\n",
        "    \"ऄ\",\n",
        "    \"अ\",\n",
        "    \"आ\",\n",
        "    \"इ\",\n",
        "    \"ई\",\n",
        "    \"उ\",\n",
        "    \"ऊ\",\n",
        "    \"ऍ\",\n",
        "    \"ऎ\",\n",
        "    \"ए\",\n",
        "    \"ऐ\",\n",
        "    \"ऑ\",\n",
        "    \"ऒ\",\n",
        "    \"ओ\",\n",
        "    \"औ\",\n",
        "    \"ऋ\",\n",
        "    \"ॠ\",\n",
        "    \"ऌ\",\n",
        "    \"ॡ\",\n",
        "    \"ॲ\",\n",
        "    \"ॐ\",\n",
        "    \"क\",\n",
        "    \"ख\",\n",
        "    \"ग\",\n",
        "    \"घ\",\n",
        "    \"ङ\",\n",
        "    \"च\",\n",
        "    \"छ\",\n",
        "    \"ज\",\n",
        "    \"झ\",\n",
        "    \"ञ\",\n",
        "    \"ट\",\n",
        "    \"ठ\",\n",
        "    \"ड\",\n",
        "    \"ढ\",\n",
        "    \"ण\",\n",
        "    \"त\",\n",
        "    \"थ\",\n",
        "    \"द\",\n",
        "    \"ध\",\n",
        "    \"न\",\n",
        "    \"ऩ\",\n",
        "    \"प\",\n",
        "    \"फ\",\n",
        "    \"ब\",\n",
        "    \"भ\",\n",
        "    \"म\",\n",
        "    \"य\",\n",
        "    \"र\",\n",
        "    \"ऱ\",\n",
        "    \"ल\",\n",
        "    \"ळ\",\n",
        "    \"ऴ\",\n",
        "    \"व\",\n",
        "    \"श\",\n",
        "    \"ष\",\n",
        "    \"स\",\n",
        "    \"ह\",\n",
        "    \"क़\",\n",
        "    \"ख़\",\n",
        "    \"ग़\",\n",
        "    \"ज़\",\n",
        "    \"ड़\",\n",
        "    \"ढ़\",\n",
        "    \"फ़\",\n",
        "    \"य़\",\n",
        "    \"्\",\n",
        "    \"ा\",\n",
        "    \"ि\",\n",
        "    \"ी\",\n",
        "    \"ु\",\n",
        "    \"ू\",\n",
        "    \"ॅ\",\n",
        "    \"ॆ\",\n",
        "    \"े\",\n",
        "    \"ै\",\n",
        "    \"ॉ\",\n",
        "    \"ॊ\",\n",
        "    \"ो\",\n",
        "    \"ौ\",\n",
        "    \"ृ\",\n",
        "    \"ॄ\",\n",
        "    \"ॢ\",\n",
        "    \"ॣ\",\n",
        "    \"ँ\",\n",
        "    \"ं\",\n",
        "    \"ः\",\n",
        "    \"़\",\n",
        "    \"॑\",\n",
        "    \"ऽ\",\n",
        "    chr(0x200C),\n",
        "    chr(0x200D),\n",
        "]"
      ],
      "metadata": {
        "id": "0dJz_LhKCAfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Script:\n",
        "    def __init__(self, language_script=devanagari_script):\n",
        "        self.graphemes = language_script\n",
        "        self.char2index = {}\n",
        "        self.index2char = {}\n",
        "        self.char2index[\"_\"] = 0\n",
        "        self.char2index[\"^\"] = 1\n",
        "        self.char2index[\"$\"] = 2\n",
        "        self.index2char[0] = \"_\"\n",
        "        self.index2char[1] = \"^\"\n",
        "        self.index2char[2] = \"$\"\n",
        "\n",
        "        for index, char in enumerate(self.graphemes):\n",
        "            self.char2index[char] = index + 3\n",
        "            self.index2char[index + 3] = char\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.char2index)\n",
        "\n",
        "    def word2vector(self, word):\n",
        "        vector = list()\n",
        "        vector.append(self.char2index[\"^\"])\n",
        "        for char in list(word):\n",
        "            if char in self.char2index:\n",
        "                vector.append(self.char2index[char])\n",
        "        vector.append(self.char2index[\"$\"])\n",
        "        vector = np.asarray(vector, dtype=np.int64)\n",
        "        return vector\n",
        "\n",
        "    def vector2word(self, vector):\n",
        "        word = list()\n",
        "        for index in vector:\n",
        "            word.append(self.index2char[index])\n",
        "        word = \"\".join(word).replace(\"_\", \"\").replace(\"^\", \"\").replace(\"$\", \"\")\n",
        "        return word"
      ],
      "metadata": {
        "id": "Cn-AvT06ChEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transliteration_Dataset(Dataset):\n",
        "    def __init__(self, data, src_script, tgt_script):\n",
        "        src_data = list()\n",
        "        tgt_data = list()\n",
        "        for sentence in data:\n",
        "            src, tgt = zip(*sentence)\n",
        "            for i in range(len(src)):\n",
        "                flag = 0\n",
        "                for src_char in src[i]:\n",
        "                    for tgt_char in tgt[i]:\n",
        "                        if (\n",
        "                            src_char not in src_script.graphemes\n",
        "                            or tgt_char not in tgt_script.graphemes\n",
        "                        ):\n",
        "                            flag = 1\n",
        "                            break\n",
        "                    if flag == 1:\n",
        "                        break\n",
        "                if flag == 0:\n",
        "                    src_data.append(src[i])\n",
        "                    tgt_data.append(tgt[i])\n",
        "\n",
        "        self.src_sript = src_script\n",
        "        self.tgt_sript = tgt_script\n",
        "        self.src = [src_script.word2vector(word) for word in src_data]\n",
        "        self.tgt = [tgt_script.word2vector(word) for word in tgt_data]\n",
        "        self.max_src_size = max([len(vector) for vector in self.src], default=0)\n",
        "        self.max_tgt_size = max([len(vector) for vector in self.tgt], default=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        src_vector = self.pad_sequence(self.src[index], self.max_src_size)\n",
        "        tgt_vector = self.pad_sequence(self.tgt[index], self.max_tgt_size)\n",
        "        return src_vector, tgt_vector, len(self.src[index])\n",
        "\n",
        "    def pad_sequence(self, vector, max_size):\n",
        "        padded_vector = np.zeros((max_size), dtype=np.int64)\n",
        "        if len(vector) > max_size:\n",
        "            padded_vector[:] = vector[:max_size]\n",
        "        else:\n",
        "            padded_vector[: len(vector)] = vector\n",
        "        return padded_vector"
      ],
      "metadata": {
        "id": "2YW3ffURNDyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Data Handling"
      ],
      "metadata": {
        "id": "iB-uQcGrnFSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Creation"
      ],
      "metadata": {
        "id": "w2pZggIygAyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_script = Script(devanagari_script)\n",
        "tgt_script = Script(english_lower_script)\n",
        "\n",
        "train_dataset = Transliteration_Dataset(train_data, src_script, tgt_script)\n",
        "dev_dataset = Transliteration_Dataset(dev_data, src_script, tgt_script)\n",
        "test_dataset = Transliteration_Dataset(test_data, src_script, tgt_script)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "QSG2KAMvpt8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Dataset Handling"
      ],
      "metadata": {
        "id": "ADeSRP-vgFQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_dataset(iterator):\n",
        "    X = list()\n",
        "    y = list()\n",
        "    for i, (src, tgt, src_size) in enumerate(iterator):\n",
        "        X.append(src.squeeze())\n",
        "        y.append(tgt.squeeze())\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "K8cIOXP2eYk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_vector_dataset(dataset_list, max_size):\n",
        "    for i, dataset in enumerate(dataset_list):\n",
        "        for j, vector in enumerate(dataset):\n",
        "            padded_vector = [0] * max_size\n",
        "            if len(vector) > max_size:\n",
        "                padded_vector[:] = vector[:max_size]\n",
        "            else:\n",
        "                padded_vector[: len(vector)] = vector\n",
        "            dataset[j] = padded_vector\n",
        "        dataset_list[i] = torch.tensor(dataset)\n",
        "    return dataset_list"
      ],
      "metadata": {
        "id": "KXyowek0rwQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, ytrain = create_vector_dataset(train_dataloader)\n",
        "Xtest, ytest = create_vector_dataset(test_dataloader)\n",
        "\n",
        "Xmax = max(len(Xtrain[0]), len(Xtest[0]))\n",
        "ymax = max(len(ytrain[0]), len(ytest[0]))\n",
        "\n",
        "Xtrain, Xtest = pad_vector_dataset([Xtrain, Xtest], Xmax)\n",
        "ytrain, ytest = pad_vector_dataset([ytrain, ytest], ymax)"
      ],
      "metadata": {
        "id": "ZkUC_MzZhoph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier"
      ],
      "metadata": {
        "id": "mk-DGOsfx0yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultiOutputClassifier(RandomForestClassifier(), n_jobs=-1)\n",
        "clf.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "WdQu_iGihmcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Score:\", clf.score(Xtrain, np.array(ytrain)))"
      ],
      "metadata": {
        "id": "nzqCS3nRiFOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Score:\", clf.score(Xtest, np.array(ytest)))"
      ],
      "metadata": {
        "id": "fMoCYKx3nGKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = clf.predict(Xtest)\n",
        "count = 0\n",
        "for i in range(len(Xtest)):\n",
        "    pred = tgt_script.vector2word(ypred[i])\n",
        "    tgt = tgt_script.vector2word(ytest[i].numpy())\n",
        "    if pred == tgt:\n",
        "        count += 1\n",
        "print(\"Accuracy:\", count / len(Xtest))"
      ],
      "metadata": {
        "id": "3YjpB_fDJYSp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}